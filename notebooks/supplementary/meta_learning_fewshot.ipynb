{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1588060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "from itertools import combinations\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b588f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: Few-Shot Learning Fundamentals\n",
    "\n",
    "### Problem Formulation\n",
    "\n",
    "**Traditional Learning:**\n",
    "- Large labeled dataset\n",
    "- Train for many iterations\n",
    "- Deploy on same distribution\n",
    "\n",
    "**Few-Shot Learning:**\n",
    "- Small labeled dataset (N-way, K-shot)\n",
    "- Quick adaptation to new task\n",
    "- Generalize to new classes\n",
    "\n",
    "### Notation\n",
    "- **N-way classification:** N different classes\n",
    "- **K-shot:** K labeled examples per class\n",
    "- **Support set:** {(x_i, y_i)} labeled examples\n",
    "- **Query set:** Unlabeled examples to classify\n",
    "\n",
    "### Example\n",
    "- 5-way 1-shot: 5 classes, 1 example each = 5 support examples\n",
    "- 5-way 5-shot: 5 classes, 5 examples each = 25 support examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic few-shot learning dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_few_shot_task(n_way: int, k_shot: int, n_query: int, \n",
    "                          feature_dim: int = 64, n_tasks: int = 100):\n",
    "    \"\"\"\n",
    "    Generate few-shot learning tasks.\n",
    "    \n",
    "    Returns:\n",
    "        support_x: (n_tasks, n_way*k_shot, feature_dim)\n",
    "        support_y: (n_tasks, n_way*k_shot)\n",
    "        query_x: (n_tasks, n_way*n_query, feature_dim)\n",
    "        query_y: (n_tasks, n_way*n_query)\n",
    "    \"\"\"\n",
    "    support_x, support_y = [], []\n",
    "    query_x, query_y = [], []\n",
    "    \n",
    "    for _ in range(n_tasks):\n",
    "        # Generate class centers\n",
    "        class_centers = np.random.randn(n_way, feature_dim)\n",
    "        \n",
    "        task_support_x, task_support_y = [], []\n",
    "        task_query_x, task_query_y = [], []\n",
    "        \n",
    "        for class_id in range(n_way):\n",
    "            center = class_centers[class_id]\n",
    "            \n",
    "            # Support examples\n",
    "            for _ in range(k_shot):\n",
    "                example = center + np.random.randn(feature_dim) * 0.1\n",
    "                task_support_x.append(example)\n",
    "                task_support_y.append(class_id)\n",
    "            \n",
    "            # Query examples\n",
    "            for _ in range(n_query):\n",
    "                example = center + np.random.randn(feature_dim) * 0.1\n",
    "                task_query_x.append(example)\n",
    "                task_query_y.append(class_id)\n",
    "        \n",
    "        support_x.append(np.array(task_support_x))\n",
    "        support_y.append(np.array(task_support_y))\n",
    "        query_x.append(np.array(task_query_x))\n",
    "        query_y.append(np.array(task_query_y))\n",
    "    \n",
    "    return (np.array(support_x), np.array(support_y), \n",
    "            np.array(query_x), np.array(query_y))\n",
    "\n",
    "# Generate dataset\n",
    "n_way, k_shot, n_query = 5, 1, 5\n",
    "support_x, support_y, query_x, query_y = generate_few_shot_task(\n",
    "    n_way, k_shot, n_query, feature_dim=64, n_tasks=1000\n",
    ")\n",
    "\n",
    "print(f\"Few-Shot Learning Dataset ({n_way}-way {k_shot}-shot):\")\n",
    "print(f\"Support set: {support_x.shape}\")\n",
    "print(f\"Query set: {query_x.shape}\")\n",
    "print(f\"Total tasks: {len(support_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e493fef",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Siamese Networks for Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4078fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(keras.Model):\n",
    "    \"\"\"Siamese network for metric learning.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, embedding_dim: int = 32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Shared embedding network\n",
    "        self.embedding_network = keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x1, x2 = inputs\n",
    "        # Get embeddings\n",
    "        z1 = self.embedding_network(x1)\n",
    "        z2 = self.embedding_network(x2)\n",
    "        \n",
    "        # Compute distance\n",
    "        distance = tf.norm(z1 - z2, axis=1)\n",
    "        return distance, z1, z2\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        \"\"\"Get embedding for input.\"\"\"\n",
    "        return self.embedding_network(x)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred, margin=1.0):\n",
    "    \"\"\"\n",
    "    Contrastive loss for Siamese networks.\n",
    "    \n",
    "    Args:\n",
    "        y_true: 1 if similar pair, 0 if dissimilar\n",
    "        y_pred: Euclidean distance\n",
    "        margin: Margin for dissimilar pairs\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    \n",
    "    # For similar pairs: minimize distance\n",
    "    similar_loss = y_true * tf.square(y_pred)\n",
    "    \n",
    "    # For dissimilar pairs: maximize distance\n",
    "    dissimilar_loss = (1 - y_true) * tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    \n",
    "    return tf.reduce_mean(similar_loss + dissimilar_loss)\n",
    "\n",
    "# Create Siamese network\n",
    "siamese_net = SiameseNetwork(input_dim=64, embedding_dim=32)\n",
    "siamese_net.compile(optimizer='adam')\n",
    "\n",
    "print(\"âœ… Siamese Network defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb828ac9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Prototypical Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetwork(keras.Model):\n",
    "    \"\"\"Prototypical Network for few-shot learning.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int, embedding_dim: int = 32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Feature extractor\n",
    "        self.feature_extractor = keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(embedding_dim)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        return self.feature_extractor(inputs, training=training)\n",
    "    \n",
    "    def compute_prototypes(self, support_x, support_y, n_way):\n",
    "        \"\"\"\n",
    "        Compute class prototypes (mean embeddings).\n",
    "        \n",
    "        Args:\n",
    "            support_x: Support examples (n_support, input_dim)\n",
    "            support_y: Support labels (n_support,)\n",
    "            n_way: Number of classes\n",
    "        \n",
    "        Returns:\n",
    "            prototypes: (n_way, embedding_dim)\n",
    "        \"\"\"\n",
    "        embeddings = self(support_x)\n",
    "        prototypes = []\n",
    "        \n",
    "        for c in range(n_way):\n",
    "            class_mask = support_y == c\n",
    "            class_embeddings = tf.boolean_mask(embeddings, class_mask)\n",
    "            prototype = tf.reduce_mean(class_embeddings, axis=0)\n",
    "            prototypes.append(prototype)\n",
    "        \n",
    "        return tf.stack(prototypes)\n",
    "    \n",
    "    def predict_query(self, prototypes, query_x):\n",
    "        \"\"\"\n",
    "        Predict labels for query examples using prototypes.\n",
    "        \n",
    "        Args:\n",
    "            prototypes: Class prototypes (n_way, embedding_dim)\n",
    "            query_x: Query examples (n_query, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "            logits: (n_query, n_way)\n",
    "        \"\"\"\n",
    "        query_embeddings = self(query_x)\n",
    "        \n",
    "        # Compute distances to all prototypes\n",
    "        distances = tf.norm(\n",
    "            query_embeddings[:, None, :] - prototypes[None, :, :],\n",
    "            axis=2\n",
    "        )\n",
    "        \n",
    "        # Convert distances to logits (negative distance)\n",
    "        logits = -distances\n",
    "        return logits\n",
    "\n",
    "# Create prototypical network\n",
    "proto_net = PrototypicalNetwork(input_dim=64, embedding_dim=32)\n",
    "proto_net.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    ")\n",
    "\n",
    "print(\"âœ… Prototypical Network defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc17696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Prototypical Network on few-shot tasks\n",
    "print(\"ðŸš€ Training Prototypical Network...\\n\")\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(20):\n",
    "    # Generate training batch\n",
    "    batch_support_x, batch_support_y, batch_query_x, batch_query_y = \\\n",
    "        generate_few_shot_task(n_way, k_shot, n_query, n_tasks=32)\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for task_idx in range(32):\n",
    "        support_x = batch_support_x[task_idx]\n",
    "        support_y = batch_support_y[task_idx]\n",
    "        query_x = batch_query_x[task_idx]\n",
    "        query_y = batch_query_y[task_idx]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Compute prototypes\n",
    "            prototypes = proto_net.compute_prototypes(support_x, support_y, n_way)\n",
    "            \n",
    "            # Predict query labels\n",
    "            logits = proto_net.predict_query(prototypes, query_x)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = proto_net.loss(query_y, logits)\n",
    "        \n",
    "        # Backpropagation\n",
    "        gradients = tape.gradient(loss, proto_net.trainable_variables)\n",
    "        proto_net.optimizer.apply_gradients(zip(gradients, proto_net.trainable_variables))\n",
    "        \n",
    "        # Compute accuracy\n",
    "        predictions = tf.argmax(logits, axis=1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(predictions == query_y, tf.float32))\n",
    "        \n",
    "        train_loss += loss.numpy()\n",
    "        train_acc += accuracy.numpy()\n",
    "    \n",
    "    train_loss /= 32\n",
    "    train_acc /= 32\n",
    "    \n",
    "    # Validation\n",
    "    val_support_x, val_support_y, val_query_x, val_query_y = \\\n",
    "        generate_few_shot_task(n_way, k_shot, n_query, n_tasks=10)\n",
    "    \n",
    "    val_acc = 0\n",
    "    for task_idx in range(10):\n",
    "        support_x = val_support_x[task_idx]\n",
    "        support_y = val_support_y[task_idx]\n",
    "        query_x = val_query_x[task_idx]\n",
    "        query_y = val_query_y[task_idx]\n",
    "        \n",
    "        prototypes = proto_net.compute_prototypes(support_x, support_y, n_way)\n",
    "        logits = proto_net.predict_query(prototypes, query_x)\n",
    "        predictions = tf.argmax(logits, axis=1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(predictions == query_y, tf.float32))\n",
    "        val_acc += accuracy.numpy()\n",
    "    \n",
    "    val_acc /= 10\n",
    "    \n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch + 1}/20 | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nâœ… Training complete!\")\n",
    "print(f\"Final validation accuracy: {val_accuracies[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0152f06",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4: Key Takeaways\n",
    "\n",
    "### Meta-Learning Approaches\n",
    "\n",
    "| Approach | Key Idea | Pros | Cons |\n",
    "|----------|----------|------|------|\n",
    "| **Metric Learning** | Learn distance metric | Simple, interpretable | Requires good embeddings |\n",
    "| **Prototypical Nets** | Mean class embeddings | Efficient, works well | Assumes Gaussian dist. |\n",
    "| **MAML** | Meta-gradient updates | Theoretically sound | Computationally expensive |\n",
    "| **Siamese Nets** | Pairwise comparison | Flexible | Requires careful pair selection |\n",
    "\n",
    "### Few-Shot Learning Challenges\n",
    "1. **Data Scarcity:** Limited labeled examples\n",
    "2. **Distribution Shift:** Domain adaptation needed\n",
    "3. **Task Variability:** Different tasks, varying difficulty\n",
    "4. **Overfitting Risk:** Small datasets â†’ high variance\n",
    "\n",
    "### Practical Applications\n",
    "- Character recognition (Omniglot dataset)\n",
    "- Image classification (miniImageNet)\n",
    "- Face recognition with new identities\n",
    "- Personalized recommendation systems\n",
    "- Rapid model adaptation to new domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_accuracies, label='Train Accuracy', linewidth=2)\n",
    "plt.plot(val_accuracies, label='Val Accuracy', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Prototypical Network Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ“š Meta-Learning & Few-Shot Learning - Summary\n",
    "==============================================\n",
    "\n",
    "âœ… Topics Covered:\n",
    "  â€¢ Few-shot learning problem formulation\n",
    "  â€¢ Metric learning and embeddings\n",
    "  â€¢ Siamese networks\n",
    "  â€¢ Prototypical networks\n",
    "  â€¢ Training on few-shot tasks\n",
    "  â€¢ Evaluation on novel classes\n",
    "\n",
    "ðŸ’¡ Key Insights:\n",
    "  â€¢ Few-shot learning enables rapid adaptation\n",
    "  â€¢ Metric learning is core to modern approaches\n",
    "  â€¢ Task-based training is more effective than standard training\n",
    "  â€¢ Prototypical networks are simple yet effective\n",
    "\n",
    "ðŸŽ¯ Next Steps:\n",
    "  1. Try different embedding dimensions\n",
    "  2. Experiment with various distance metrics\n",
    "  3. Apply to real datasets (Omniglot, miniImageNet)\n",
    "  4. Implement MAML for better performance\n",
    "  5. Explore multi-task meta-learning\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
