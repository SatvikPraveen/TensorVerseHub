{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 gans with tensorflow keras\n",
    "**Location: TensorVerseHub/notebooks/05_generative_models/13_gans_with_tensorflow_keras.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs with TensorFlow/tf.keras\n",
    "\n",
    "**File Location:** `notebooks/05_generative_models/13_gans_with_tensorflow_keras.ipynb`\n",
    "\n",
    "Master Generative Adversarial Networks (GANs) using tf.keras Sequential and Functional APIs. Build, train, and optimize various GAN architectures including DCGAN, conditional GANs, and Wasserstein GANs for image generation and data synthesis.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand GAN architecture and adversarial training principles\n",
    "- Implement DCGAN using tf.keras Sequential and Functional APIs\n",
    "- Build conditional GANs for controlled generation\n",
    "- Master Wasserstein GAN with gradient penalty (WGAN-GP)\n",
    "- Apply advanced GAN training techniques and stabilization methods\n",
    "- Generate high-quality synthetic images and data\n",
    "\n",
    "---\n",
    "\n",
    "## 1. GAN Fundamentals and Basic Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Basic GAN implementation using tf.keras Sequential API\n",
    "class BasicGAN:\n",
    "    \"\"\"Basic GAN implementation demonstrating core concepts\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, img_shape=(28, 28, 1)):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = img_shape\n",
    "        self.img_height, self.img_width, self.channels = img_shape\n",
    "        \n",
    "        # Build models\n",
    "        self.generator = self.build_generator()\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        \n",
    "        # Compile discriminator\n",
    "        self.discriminator.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Build combined model for generator training\n",
    "        self.discriminator.trainable = False\n",
    "        z = tf.keras.Input(shape=(self.latent_dim,))\n",
    "        fake_img = self.generator(z)\n",
    "        validity = self.discriminator(fake_img)\n",
    "        \n",
    "        self.combined = tf.keras.Model(z, validity)\n",
    "        self.combined.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(0.0002, 0.5),\n",
    "            loss='binary_crossentropy'\n",
    "        )\n",
    "    \n",
    "    def build_generator(self):\n",
    "        \"\"\"Build generator using Sequential API\"\"\"\n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "            # Foundation for 7x7 image\n",
    "            layers.Dense(7 * 7 * 256, input_shape=(self.latent_dim,)),\n",
    "            layers.Reshape((7, 7, 256)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            # Upsample to 14x14\n",
    "            layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            # Upsample to 28x28\n",
    "            layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            # Final layer - output image\n",
    "            layers.Conv2DTranspose(self.channels, (5, 5), strides=(1, 1), \n",
    "                                 padding='same', activation='tanh'),\n",
    "        ], name='generator')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        \"\"\"Build discriminator using Sequential API\"\"\"\n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                         input_shape=self.img_shape),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ], name='discriminator')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_step(self, real_images, batch_size):\n",
    "        \"\"\"Single training step for GAN\"\"\"\n",
    "        \n",
    "        # Generate fake images\n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "        fake_images = self.generator(noise, training=False)\n",
    "        \n",
    "        # Labels\n",
    "        real_labels = tf.ones((batch_size, 1))\n",
    "        fake_labels = tf.zeros((batch_size, 1))\n",
    "        \n",
    "        # Train discriminator\n",
    "        d_loss_real = self.discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = self.discriminator.train_on_batch(fake_images, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "        valid_labels = tf.ones((batch_size, 1))\n",
    "        g_loss = self.combined.train_on_batch(noise, valid_labels)\n",
    "        \n",
    "        return d_loss, g_loss\n",
    "    \n",
    "    def generate_images(self, n_samples=25):\n",
    "        \"\"\"Generate sample images\"\"\"\n",
    "        noise = tf.random.normal([n_samples, self.latent_dim])\n",
    "        generated_images = self.generator(noise, training=False)\n",
    "        return 0.5 * generated_images + 0.5  # Rescale to [0,1]\n",
    "\n",
    "# Load MNIST data\n",
    "def load_mnist_data():\n",
    "    \"\"\"Load and preprocess MNIST dataset\"\"\"\n",
    "    (X_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # Normalize to [-1, 1] for tanh activation\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    \n",
    "    print(f\"MNIST loaded: {X_train.shape}, range: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
    "    return X_train, y_train\n",
    "\n",
    "# Test basic GAN\n",
    "X_train, y_train = load_mnist_data()\n",
    "basic_gan = BasicGAN(latent_dim=100, img_shape=(28, 28, 1))\n",
    "\n",
    "print(\"Generator Architecture:\")\n",
    "basic_gan.generator.summary()\n",
    "print(\"\\nDiscriminator Architecture:\")\n",
    "basic_gan.discriminator.summary()\n",
    "\n",
    "# Test generation before training\n",
    "sample_images = basic_gan.generate_images(9)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(sample_images[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Random Noise Generated Images (Before Training)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DCGAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Convolutional GAN (DCGAN) - improved architecture\n",
    "class DCGAN:\n",
    "    \"\"\"DCGAN implementation with best practices\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, img_shape=(64, 64, 3)):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = img_shape\n",
    "        self.img_height, self.img_width, self.channels = img_shape\n",
    "        \n",
    "        # Optimizers with different learning rates\n",
    "        self.g_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        self.d_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        \n",
    "        # Build models\n",
    "        self.generator = self.build_dcgan_generator()\n",
    "        self.discriminator = self.build_dcgan_discriminator()\n",
    "        \n",
    "        # Loss function\n",
    "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        \n",
    "    def build_dcgan_generator(self):\n",
    "        \"\"\"Build DCGAN generator with proper architecture\"\"\"\n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "            # Project and reshape\n",
    "            layers.Dense(4 * 4 * 1024, use_bias=False, input_shape=(self.latent_dim,)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(),\n",
    "            layers.Reshape((4, 4, 1024)),\n",
    "            \n",
    "            # 4x4 -> 8x8\n",
    "            layers.Conv2DTranspose(512, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(),\n",
    "            \n",
    "            # 8x8 -> 16x16\n",
    "            layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(),\n",
    "            \n",
    "            # 16x16 -> 32x32\n",
    "            layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(),\n",
    "            \n",
    "            # 32x32 -> 64x64\n",
    "            layers.Conv2DTranspose(self.channels, (5, 5), strides=(2, 2), \n",
    "                                 padding='same', use_bias=False, activation='tanh')\n",
    "        ], name='dcgan_generator')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_dcgan_discriminator(self):\n",
    "        \"\"\"Build DCGAN discriminator with proper architecture\"\"\"\n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "            # 64x64 -> 32x32\n",
    "            layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', \n",
    "                         input_shape=self.img_shape),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            # 32x32 -> 16x16\n",
    "            layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            # 16x16 -> 8x8\n",
    "            layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            # 8x8 -> 4x4\n",
    "            layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1)  # No sigmoid - using from_logits=True\n",
    "        ], name='dcgan_discriminator')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        \"\"\"Calculate discriminator loss\"\"\"\n",
    "        real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        return real_loss + fake_loss\n",
    "    \n",
    "    def generator_loss(self, fake_output):\n",
    "        \"\"\"Calculate generator loss\"\"\"\n",
    "        return self.cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, real_images, batch_size):\n",
    "        \"\"\"Optimized training step using tf.function\"\"\"\n",
    "        \n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = self.generator(noise, training=True)\n",
    "            \n",
    "            real_output = self.discriminator(real_images, training=True)\n",
    "            fake_output = self.discriminator(generated_images, training=True)\n",
    "            \n",
    "            gen_loss = self.generator_loss(fake_output)\n",
    "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        # Apply gradients\n",
    "        self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return gen_loss, disc_loss\n",
    "\n",
    "# Prepare CIFAR-10 data for DCGAN\n",
    "def load_cifar10_data():\n",
    "    \"\"\"Load and preprocess CIFAR-10 dataset\"\"\"\n",
    "    (X_train, y_train), _ = tf.keras.datasets.cifar10.load_data()\n",
    "    \n",
    "    # Normalize to [-1, 1]\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    \n",
    "    # Resize to 64x64\n",
    "    X_train = tf.image.resize(X_train, [64, 64]).numpy()\n",
    "    \n",
    "    print(f\"CIFAR-10 loaded: {X_train.shape}, range: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
    "    return X_train, y_train\n",
    "\n",
    "# Training function for DCGAN\n",
    "def train_dcgan(dcgan, dataset, epochs=50, batch_size=128, save_interval=10):\n",
    "    \"\"\"Train DCGAN with monitoring\"\"\"\n",
    "    \n",
    "    # Training history\n",
    "    history = {'g_loss': [], 'd_loss': []}\n",
    "    \n",
    "    # Fixed noise for consistent monitoring\n",
    "    fixed_noise = tf.random.normal([16, dcgan.latent_dim])\n",
    "    \n",
    "    batches_per_epoch = len(dataset) // batch_size\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Shuffle data\n",
    "        np.random.shuffle(dataset)\n",
    "        \n",
    "        epoch_g_loss = []\n",
    "        epoch_d_loss = []\n",
    "        \n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "            # Get batch\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            real_images = dataset[start_idx:end_idx]\n",
    "            \n",
    "            # Train step\n",
    "            g_loss, d_loss = dcgan.train_step(real_images, batch_size)\n",
    "            \n",
    "            epoch_g_loss.append(g_loss.numpy())\n",
    "            epoch_d_loss.append(d_loss.numpy())\n",
    "        \n",
    "        # Record history\n",
    "        history['g_loss'].append(np.mean(epoch_g_loss))\n",
    "        history['d_loss'].append(np.mean(epoch_d_loss))\n",
    "        \n",
    "        # Print progress\n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - {epoch_time:.2f}s - \"\n",
    "              f\"G_loss: {history['g_loss'][-1]:.4f}, D_loss: {history['d_loss'][-1]:.4f}\")\n",
    "        \n",
    "        # Generate sample images\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            generate_and_save_images(dcgan.generator, epoch + 1, fixed_noise)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def generate_and_save_images(generator, epoch, test_input):\n",
    "    \"\"\"Generate and display sample images\"\"\"\n",
    "    predictions = generator(test_input, training=False)\n",
    "    predictions = 0.5 * predictions + 0.5  # Rescale to [0,1]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        if predictions.shape[-1] == 1:\n",
    "            plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(predictions[i])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Generated Images - Epoch {epoch}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test DCGAN\n",
    "print(\"=== DCGAN Implementation ===\")\n",
    "\n",
    "# Use MNIST for faster training demonstration\n",
    "dcgan = DCGAN(latent_dim=100, img_shape=(28, 28, 1))\n",
    "\n",
    "print(\"DCGAN Generator Architecture:\")\n",
    "dcgan.generator.summary()\n",
    "print(\"\\nDCGAN Discriminator Architecture:\")\n",
    "dcgan.discriminator.summary()\n",
    "\n",
    "# Train for a few epochs (demo)\n",
    "print(\"\\nTraining DCGAN (demo with 3 epochs)...\")\n",
    "dcgan_history = train_dcgan(dcgan, X_train[:5000], epochs=3, batch_size=64, save_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conditional GAN (cGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional GAN implementation\n",
    "class ConditionalGAN:\n",
    "    \"\"\"Conditional GAN for controlled generation\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, num_classes=10, img_shape=(28, 28, 1)):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.img_shape = img_shape\n",
    "        self.img_height, self.img_width, self.channels = img_shape\n",
    "        \n",
    "        # Optimizers\n",
    "        self.g_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        self.d_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)\n",
    "        \n",
    "        # Build models\n",
    "        self.generator = self.build_conditional_generator()\n",
    "        self.discriminator = self.build_conditional_discriminator()\n",
    "        \n",
    "        # Loss function\n",
    "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        \n",
    "    def build_conditional_generator(self):\n",
    "        \"\"\"Build conditional generator using Functional API\"\"\"\n",
    "        \n",
    "        # Noise input\n",
    "        noise_input = layers.Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        # Label input\n",
    "        label_input = layers.Input(shape=(1,))\n",
    "        label_embedding = layers.Embedding(self.num_classes, self.latent_dim)(label_input)\n",
    "        label_embedding = layers.Flatten()(label_embedding)\n",
    "        \n",
    "        # Combine noise and label\n",
    "        combined_input = layers.Multiply()([noise_input, label_embedding])\n",
    "        \n",
    "        # Generator architecture\n",
    "        x = layers.Dense(7 * 7 * 256)(combined_input)\n",
    "        x = layers.Reshape((7, 7, 256))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        \n",
    "        x = layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        \n",
    "        x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        \n",
    "        output = layers.Conv2DTranspose(self.channels, (5, 5), strides=(1, 1), \n",
    "                                      padding='same', activation='tanh')(x)\n",
    "        \n",
    "        model = tf.keras.Model([noise_input, label_input], output, name='conditional_generator')\n",
    "        return model\n",
    "    \n",
    "    def build_conditional_discriminator(self):\n",
    "        \"\"\"Build conditional discriminator using Functional API\"\"\"\n",
    "        \n",
    "        # Image input\n",
    "        img_input = layers.Input(shape=self.img_shape)\n",
    "        \n",
    "        # Label input\n",
    "        label_input = layers.Input(shape=(1,))\n",
    "        label_embedding = layers.Embedding(self.num_classes, np.prod(self.img_shape))(label_input)\n",
    "        label_embedding = layers.Flatten()(label_embedding)\n",
    "        label_embedding = layers.Reshape(self.img_shape)(label_embedding)\n",
    "        \n",
    "        # Combine image and label\n",
    "        combined_input = layers.Concatenate(axis=-1)([img_input, label_embedding])\n",
    "        \n",
    "        # Discriminator architecture\n",
    "        x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(combined_input)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "        \n",
    "        x = layers.Flatten()(x)\n",
    "        output = layers.Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model([img_input, label_input], output, name='conditional_discriminator')\n",
    "        return model\n",
    "    \n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        \"\"\"Calculate discriminator loss\"\"\"\n",
    "        real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        return real_loss + fake_loss\n",
    "    \n",
    "    def generator_loss(self, fake_output):\n",
    "        \"\"\"Calculate generator loss\"\"\"\n",
    "        return self.cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, real_images, real_labels, batch_size):\n",
    "        \"\"\"Training step for conditional GAN\"\"\"\n",
    "        \n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_images = self.generator([noise, real_labels], training=True)\n",
    "            \n",
    "            real_output = self.discriminator([real_images, real_labels], training=True)\n",
    "            fake_output = self.discriminator([generated_images, real_labels], training=True)\n",
    "            \n",
    "            gen_loss = self.generator_loss(fake_output)\n",
    "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "        # Apply gradients\n",
    "        gen_gradients = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        disc_gradients = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        self.g_optimizer.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
    "        self.d_optimizer.apply_gradients(zip(disc_gradients, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return gen_loss, disc_loss\n",
    "    \n",
    "    def generate_class_samples(self, class_labels, n_samples_per_class=5):\n",
    "        \"\"\"Generate samples for specific classes\"\"\"\n",
    "        \n",
    "        total_samples = len(class_labels) * n_samples_per_class\n",
    "        noise = tf.random.normal([total_samples, self.latent_dim])\n",
    "        \n",
    "        # Repeat labels for each sample\n",
    "        expanded_labels = np.repeat(class_labels, n_samples_per_class)\n",
    "        expanded_labels = expanded_labels.reshape(-1, 1)\n",
    "        \n",
    "        generated_images = self.generator([noise, expanded_labels], training=False)\n",
    "        generated_images = 0.5 * generated_images + 0.5  # Rescale\n",
    "        \n",
    "        return generated_images, expanded_labels\n",
    "\n",
    "# Train conditional GAN\n",
    "def train_conditional_gan(cgan, images, labels, epochs=20, batch_size=128):\n",
    "    \"\"\"Train conditional GAN\"\"\"\n",
    "    \n",
    "    history = {'g_loss': [], 'd_loss': []}\n",
    "    batches_per_epoch = len(images) // batch_size\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Shuffle data\n",
    "        indices = np.random.permutation(len(images))\n",
    "        images_shuffled = images[indices]\n",
    "        labels_shuffled = labels[indices]\n",
    "        \n",
    "        epoch_g_loss = []\n",
    "        epoch_d_loss = []\n",
    "        \n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            \n",
    "            real_images = images_shuffled[start_idx:end_idx]\n",
    "            real_labels = labels_shuffled[start_idx:end_idx]\n",
    "            \n",
    "            g_loss, d_loss = cgan.train_step(real_images, real_labels, batch_size)\n",
    "            \n",
    "            epoch_g_loss.append(g_loss.numpy())\n",
    "            epoch_d_loss.append(d_loss.numpy())\n",
    "        \n",
    "        history['g_loss'].append(np.mean(epoch_g_loss))\n",
    "        history['d_loss'].append(np.mean(epoch_d_loss))\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - {epoch_time:.2f}s - \"\n",
    "              f\"G_loss: {history['g_loss'][-1]:.4f}, D_loss: {history['d_loss'][-1]:.4f}\")\n",
    "        \n",
    "        # Generate class-specific samples\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            generate_class_specific_images(cgan, epoch + 1)\n",
    "    \n",
    "    return history\n",
    "\n",
    "def generate_class_specific_images(cgan, epoch):\n",
    "    \"\"\"Generate images for each class\"\"\"\n",
    "    \n",
    "    class_labels = list(range(min(10, cgan.num_classes)))  # Show first 10 classes\n",
    "    generated_images, labels = cgan.generate_class_samples(class_labels, n_samples_per_class=1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (img, label) in enumerate(zip(generated_images[:10], labels[:10])):\n",
    "        if generated_images.shape[-1] == 1:\n",
    "            axes[i].imshow(img[:, :, 0], cmap='gray')\n",
    "        else:\n",
    "            axes[i].imshow(img)\n",
    "        axes[i].set_title(f'Class {label[0]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Class-Conditional Generation - Epoch {epoch}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Test Conditional GAN\n",
    "print(\"=== Conditional GAN Implementation ===\")\n",
    "\n",
    "# Initialize conditional GAN\n",
    "cgan = ConditionalGAN(latent_dim=100, num_classes=10, img_shape=(28, 28, 1))\n",
    "\n",
    "print(\"Conditional Generator Architecture:\")\n",
    "cgan.generator.summary()\n",
    "print(\"\\nConditional Discriminator Architecture:\")\n",
    "cgan.discriminator.summary()\n",
    "\n",
    "# Train for a few epochs (demo)\n",
    "print(\"\\nTraining Conditional GAN (demo with 3 epochs)...\")\n",
    "cgan_history = train_conditional_gan(cgan, X_train[:5000], y_train[:5000], epochs=3, batch_size=64)\n",
    "\n",
    "# Test class-specific generation\n",
    "print(\"\\nTesting class-specific generation:\")\n",
    "test_classes = [0, 1, 2, 3, 4]  # Generate digits 0-4\n",
    "generated_samples, sample_labels = cgan.generate_class_samples(test_classes, n_samples_per_class=2)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(generated_samples[i, :, :, 0], cmap='gray')\n",
    "    plt.title(f'Class {sample_labels[i][0]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Conditional Generation Results')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wasserstein GAN with Gradient Penalty (WGAN-GP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wasserstein GAN with Gradient Penalty\n",
    "class WGANGP:\n",
    "    \"\"\"Wasserstein GAN with Gradient Penalty for stable training\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, img_shape=(28, 28, 1), critic_iterations=5, lambda_gp=10):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = img_shape\n",
    "        self.critic_iterations = critic_iterations\n",
    "        self.lambda_gp = lambda_gp\n",
    "        \n",
    "        # Build models\n",
    "        self.generator = self.build_wgan_generator()\n",
    "        self.critic = self.build_wgan_critic()\n",
    "        \n",
    "        # Optimizers\n",
    "        self.g_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.0, beta_2=0.9)\n",
    "        self.c_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.0, beta_2=0.9)\n",
    "    \n",
    "    def build_wgan_generator(self):\n",
    "        \"\"\"Build Wasserstein GAN generator\"\"\"\n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Dense(7 * 7 * 256, input_shape=(self.latent_dim,)),\n",
    "            layers.Reshape((7, 7, 256)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            \n",
    "            layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            \n",
    "            layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            \n",
    "            layers.Conv2DTranspose(self.img_shape[-1], (5, 5), strides=(1, 1), \n",
    "                                 padding='same', activation='tanh'),\n",
    "        ], name='wgan_generator')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def build_wgan_critic(self):\n",
    "        \"\"\"Build Wasserstein GAN critic (no sigmoid activation)\"\"\"\n",
    "        \n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                         input_shape=self.img_shape),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            \n",
    "            layers.Flatten(),\n",
    "            layers.Dense(1)  # No activation - output raw score\n",
    "        ], name='wgan_critic')\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def gradient_penalty(self, real_images, fake_images, batch_size):\n",
    "        \"\"\"Calculate gradient penalty for WGAN-GP\"\"\"\n",
    "        \n",
    "        # Random interpolation between real and fake images\n",
    "        alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        interpolated = alpha * real_images + (1 - alpha) * fake_images\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(interpolated)\n",
    "            critic_interpolated = self.critic(interpolated, training=True)\n",
    "        \n",
    "        # Calculate gradients\n",
    "        gradients = tape.gradient(critic_interpolated, interpolated)\n",
    "        gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
    "        gradient_penalty = tf.reduce_mean((gradients_norm - 1.0) ** 2)\n",
    "        \n",
    "        return gradient_penalty\n",
    "    \n",
    "    def generator_loss(self, fake_output):\n",
    "        \"\"\"Generator loss for WGAN\"\"\"\n",
    "        return -tf.reduce_mean(fake_output)\n",
    "    \n",
    "    def critic_loss(self, real_output, fake_output):\n",
    "        \"\"\"Critic loss for WGAN\"\"\"\n",
    "        return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "    \n",
    "    @tf.function\n",
    "    def train_critic_step(self, real_images, batch_size):\n",
    "        \"\"\"Train critic for one step\"\"\"\n",
    "        \n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "        \n",
    "        with tf.GradientTape() as critic_tape:\n",
    "            fake_images = self.generator(noise, training=False)\n",
    "            \n",
    "            real_output = self.critic(real_images, training=True)\n",
    "            fake_output = self.critic(fake_images, training=True)\n",
    "            \n",
    "            critic_loss = self.critic_loss(real_output, fake_output)\n",
    "            gp = self.gradient_penalty(real_images, fake_images, batch_size)\n",
    "            critic_loss += self.lambda_gp * gp\n",
    "        \n",
    "        critic_gradients = critic_tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "        self.c_optimizer.apply_gradients(zip(critic_gradients, self.critic.trainable_variables))\n",
    "        \n",
    "        return critic_loss, gp\n",
    "    \n",
    "    @tf.function\n",
    "    def train_generator_step(self, batch_size):\n",
    "        \"\"\"Train generator for one step\"\"\"\n",
    "        \n",
    "        noise = tf.random.normal([batch_size, self.latent_dim])\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            fake_images = self.generator(noise, training=True)\n",
    "            fake_output = self.critic(fake_images, training=False)\n",
    "            \n",
    "            gen_loss = self.generator_loss(fake_output)\n",
    "        \n",
    "        gen_gradients = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
    "        \n",
    "        return gen_loss\n",
    "    \n",
    "    def train_step(self, real_images, batch_size):\n",
    "        \"\"\"Full training step for WGAN-GP\"\"\"\n",
    "        \n",
    "        # Train critic multiple times\n",
    "        critic_losses = []\n",
    "        gradient_penalties = []\n",
    "        \n",
    "        for _ in range(self.critic_iterations):\n",
    "            c_loss, gp = self.train_critic_step(real_images, batch_size)\n",
    "            critic_losses.append(c_loss.numpy())\n",
    "            gradient_penalties.append(gp.numpy())\n",
    "        \n",
    "        # Train generator once\n",
    "        g_loss = self.train_generator_step(batch_size)\n",
    "        \n",
    "        return np.mean(critic_losses), g_loss.numpy(), np.mean(gradient_penalties)\n",
    "\n",
    "# Training function for WGAN-GP\n",
    "def train_wgan_gp(wgan, dataset, epochs=20, batch_size=128):\n",
    "    \"\"\"Train WGAN-GP with monitoring\"\"\"\n",
    "    \n",
    "    history = {'c_loss': [], 'g_loss': [], 'gp': []}\n",
    "    fixed_noise = tf.random.normal([16, wgan.latent_dim])\n",
    "    \n",
    "    batches_per_epoch = len(dataset) // batch_size\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        np.random.shuffle(dataset)\n",
    "        \n",
    "        epoch_c_loss = []\n",
    "        epoch_g_loss = []\n",
    "        epoch_gp = []\n",
    "        \n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            real_images = dataset[start_idx:end_idx]\n",
    "            \n",
    "            c_loss, g_loss, gp = wgan.train_step(real_images, batch_size)\n",
    "            \n",
    "            epoch_c_loss.append(c_loss)\n",
    "            epoch_g_loss.append(g_loss)\n",
    "            epoch_gp.append(gp)\n",
    "        \n",
    "        history['c_loss'].append(np.mean(epoch_c_loss))\n",
    "        history['g_loss'].append(np.mean(epoch_g_loss))\n",
    "        history['gp'].append(np.mean(epoch_gp))\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - {epoch_time:.2f}s - \"\n",
    "              f\"C_loss: {history['c_loss'][-1]:.4f}, G_loss: {history['g_loss'][-1]:.4f}, \"\n",
    "              f\"GP: {history['gp'][-1]:.4f}\")\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            generate_and_save_images(wgan.generator, epoch + 1, fixed_noise)\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Test WGAN-GP\n",
    "print(\"=== WGAN-GP Implementation ===\")\n",
    "\n",
    "wgan_gp = WGANGP(latent_dim=100, img_shape=(28, 28, 1), critic_iterations=5, lambda_gp=10)\n",
    "\n",
    "print(\"WGAN-GP Generator Architecture:\")\n",
    "wgan_gp.generator.summary()\n",
    "print(\"\\nWGAN-GP Critic Architecture:\")\n",
    "wgan_gp.critic.summary()\n",
    "\n",
    "# Train for a few epochs (demo)\n",
    "print(\"\\nTraining WGAN-GP (demo with 3 epochs)...\")\n",
    "wgan_history = train_wgan_gp(wgan_gp, X_train[:5000], epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Training Techniques and Stabilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced GAN training techniques\n",
    "class StableGANTrainer:\n",
    "    \"\"\"Advanced trainer with stabilization techniques\"\"\"\n",
    "    \n",
    "    def __init__(self, gan_type='dcgan'):\n",
    "        self.gan_type = gan_type\n",
    "        self.training_history = {\n",
    "            'g_loss': [], 'd_loss': [], 'fid_scores': [], 'is_scores': []\n",
    "        }\n",
    "    \n",
    "    def spectral_normalization(self, layer):\n",
    "        \"\"\"Apply spectral normalization to layer\"\"\"\n",
    "        return tf.keras.utils.get_custom_objects().get('SpectralNormalization', layer)\n",
    "    \n",
    "    def progressive_growing_schedule(self, current_epoch, total_epochs):\n",
    "        \"\"\"Progressive growing schedule for resolution\"\"\"\n",
    "        phases = [4, 8, 16, 32]  # Resolution phases\n",
    "        phase_length = total_epochs // len(phases)\n",
    "        current_phase = min(current_epoch // phase_length, len(phases) - 1)\n",
    "        return phases[current_phase]\n",
    "    \n",
    "    def adaptive_learning_rate(self, g_loss, d_loss, base_lr=0.0002):\n",
    "        \"\"\"Adaptive learning rate based on loss balance\"\"\"\n",
    "        \n",
    "        # If discriminator is too strong, reduce its learning rate\n",
    "        if d_loss < 0.1 and g_loss > 2.0:\n",
    "            d_lr = base_lr * 0.5\n",
    "            g_lr = base_lr * 1.5\n",
    "        # If generator is too strong, reduce its learning rate  \n",
    "        elif g_loss < 0.1 and d_loss > 2.0:\n",
    "            g_lr = base_lr * 0.5\n",
    "            d_lr = base_lr * 1.5\n",
    "        else:\n",
    "            g_lr = base_lr\n",
    "            d_lr = base_lr\n",
    "        \n",
    "        return g_lr, d_lr\n",
    "    \n",
    "    def label_smoothing(self, labels, smoothing=0.1):\n",
    "        \"\"\"Apply label smoothing to reduce discriminator overconfidence\"\"\"\n",
    "        \n",
    "        if smoothing > 0:\n",
    "            # Smooth positive labels\n",
    "            labels = labels * (1 - smoothing) + 0.5 * smoothing\n",
    "        \n",
    "        return labels\n",
    "    \n",
    "    def feature_matching_loss(self, real_features, fake_features):\n",
    "        \"\"\"Feature matching loss for stable training\"\"\"\n",
    "        \n",
    "        return tf.reduce_mean(tf.abs(tf.reduce_mean(real_features, axis=0) - \n",
    "                                   tf.reduce_mean(fake_features, axis=0)))\n",
    "    \n",
    "    def diversity_loss(self, generated_images, batch_size):\n",
    "        \"\"\"Encourage diversity in generated images\"\"\"\n",
    "        \n",
    "        # Compute pairwise distances\n",
    "        flattened = tf.reshape(generated_images, [batch_size, -1])\n",
    "        \n",
    "        # L2 distance matrix\n",
    "        distances = tf.norm(flattened[:, None] - flattened[None, :], axis=2)\n",
    "        \n",
    "        # Encourage larger minimum distance\n",
    "        min_distances = tf.reduce_min(distances + tf.eye(batch_size) * 1e6, axis=1)\n",
    "        diversity_loss = -tf.reduce_mean(min_distances)\n",
    "        \n",
    "        return diversity_loss\n",
    "\n",
    "# Model evaluation metrics\n",
    "class GANEvaluator:\n",
    "    \"\"\"Comprehensive GAN evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def calculate_fid_score(self, real_images, generated_images, batch_size=50):\n",
    "        \"\"\"Calculate Fr√©chet Inception Distance (simplified)\"\"\"\n",
    "        \n",
    "        # In practice, use pre-trained InceptionV3\n",
    "        # This is a simplified version for demonstration\n",
    "        \n",
    "        def get_activations(images):\n",
    "            # Simple feature extractor (replace with InceptionV3 in practice)\n",
    "            model = tf.keras.Sequential([\n",
    "                layers.Conv2D(32, 3, activation='relu'),\n",
    "                layers.GlobalAveragePooling2D(),\n",
    "                layers.Dense(128, activation='relu')\n",
    "            ])\n",
    "            \n",
    "            return model(images)\n",
    "        \n",
    "        real_features = get_activations(real_images[:batch_size])\n",
    "        fake_features = get_activations(generated_images[:batch_size])\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mu_real = tf.reduce_mean(real_features, axis=0)\n",
    "        mu_fake = tf.reduce_mean(fake_features, axis=0)\n",
    "        \n",
    "        sigma_real = tfp.stats.covariance(real_features)\n",
    "        sigma_fake = tfp.stats.covariance(fake_features)\n",
    "        \n",
    "        # FID calculation (simplified)\n",
    "        diff = mu_real - mu_fake\n",
    "        fid = tf.reduce_sum(diff ** 2) + tf.linalg.trace(sigma_real + sigma_fake - 2 * tf.linalg.sqrtm(sigma_real @ sigma_fake))\n",
    "        \n",
    "        return fid.numpy()\n",
    "    \n",
    "    def calculate_inception_score(self, generated_images, batch_size=50):\n",
    "        \"\"\"Calculate Inception Score (simplified)\"\"\"\n",
    "        \n",
    "        # Simplified version - in practice use InceptionV3\n",
    "        def get_predictions(images):\n",
    "            # Simple classifier (replace with InceptionV3 in practice)\n",
    "            model = tf.keras.Sequential([\n",
    "                layers.Conv2D(32, 3, activation='relu'),\n",
    "                layers.GlobalAveragePooling2D(),\n",
    "                layers.Dense(10, activation='softmax')  # 10 classes for demo\n",
    "            ])\n",
    "            \n",
    "            return model(images)\n",
    "        \n",
    "        predictions = get_predictions(generated_images[:batch_size])\n",
    "        \n",
    "        # Calculate IS\n",
    "        py = tf.reduce_mean(predictions, axis=0)\n",
    "        kl_div = predictions * (tf.math.log(predictions) - tf.math.log(py))\n",
    "        is_score = tf.exp(tf.reduce_mean(tf.reduce_sum(kl_div, axis=1)))\n",
    "        \n",
    "        return is_score.numpy()\n",
    "    \n",
    "    def visual_quality_assessment(self, generated_images, grid_size=(5, 5)):\n",
    "        \"\"\"Visual quality assessment\"\"\"\n",
    "        \n",
    "        n_samples = grid_size[0] * grid_size[1]\n",
    "        samples = generated_images[:n_samples]\n",
    "        \n",
    "        plt.figure(figsize=(12, 12))\n",
    "        for i in range(n_samples):\n",
    "            plt.subplot(grid_size[0], grid_size[1], i + 1)\n",
    "            \n",
    "            if samples.shape[-1] == 1:\n",
    "                plt.imshow(samples[i, :, :, 0], cmap='gray')\n",
    "            else:\n",
    "                plt.imshow(samples[i])\n",
    "            \n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.suptitle('Generated Images Quality Assessment')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Training with advanced techniques\n",
    "def train_with_stabilization(gan, dataset, epochs=50, batch_size=128):\n",
    "    \"\"\"Train GAN with advanced stabilization techniques\"\"\"\n",
    "    \n",
    "    trainer = StableGANTrainer('dcgan')\n",
    "    evaluator = GANEvaluator()\n",
    "    \n",
    "    # Training parameters\n",
    "    base_lr = 0.0002\n",
    "    label_smoothing = 0.1\n",
    "    \n",
    "    history = {'g_loss': [], 'd_loss': [], 'lr_g': [], 'lr_d': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        np.random.shuffle(dataset)\n",
    "        batches_per_epoch = len(dataset) // batch_size\n",
    "        \n",
    "        epoch_g_loss = []\n",
    "        epoch_d_loss = []\n",
    "        \n",
    "        for batch_idx in range(batches_per_epoch):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            real_images = dataset[start_idx:end_idx]\n",
    "            \n",
    "            # Generate fake images\n",
    "            noise = tf.random.normal([batch_size, gan.latent_dim])\n",
    "            fake_images = gan.generator(noise, training=False)\n",
    "            \n",
    "            # Apply label smoothing\n",
    "            real_labels = trainer.label_smoothing(tf.ones((batch_size, 1)), label_smoothing)\n",
    "            fake_labels = tf.zeros((batch_size, 1))\n",
    "            \n",
    "            # Train discriminator\n",
    "            with tf.GradientTape() as disc_tape:\n",
    "                real_output = gan.discriminator(real_images, training=True)\n",
    "                fake_output = gan.discriminator(fake_images, training=True)\n",
    "                \n",
    "                d_loss_real = tf.keras.losses.binary_crossentropy(real_labels, real_output, from_logits=True)\n",
    "                d_loss_fake = tf.keras.losses.binary_crossentropy(fake_labels, fake_output, from_logits=True)\n",
    "                d_loss = tf.reduce_mean(d_loss_real) + tf.reduce_mean(d_loss_fake)\n",
    "            \n",
    "            # Train generator\n",
    "            with tf.GradientTape() as gen_tape:\n",
    "                fake_images = gan.generator(noise, training=True)\n",
    "                fake_output = gan.discriminator(fake_images, training=False)\n",
    "                \n",
    "                g_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(\n",
    "                    tf.ones_like(fake_output), fake_output, from_logits=True))\n",
    "                \n",
    "                # Add diversity loss\n",
    "                diversity_loss = trainer.diversity_loss(fake_images, batch_size)\n",
    "                g_loss += 0.1 * diversity_loss\n",
    "            \n",
    "            # Adaptive learning rate\n",
    "            g_lr, d_lr = trainer.adaptive_learning_rate(g_loss.numpy(), d_loss.numpy(), base_lr)\n",
    "            \n",
    "            # Apply gradients\n",
    "            d_gradients = disc_tape.gradient(d_loss, gan.discriminator.trainable_variables)\n",
    "            g_gradients = gen_tape.gradient(g_loss, gan.generator.trainable_variables)\n",
    "            \n",
    "            # Update with adaptive learning rates\n",
    "            gan.d_optimizer.learning_rate = d_lr\n",
    "            gan.g_optimizer.learning_rate = g_lr\n",
    "            \n",
    "            gan.d_optimizer.apply_gradients(zip(d_gradients, gan.discriminator.trainable_variables))\n",
    "            gan.g_optimizer.apply_gradients(zip(g_gradients, gan.generator.trainable_variables))\n",
    "            \n",
    "            epoch_g_loss.append(g_loss.numpy())\n",
    "            epoch_d_loss.append(d_loss.numpy())\n",
    "        \n",
    "        # Record history\n",
    "        history['g_loss'].append(np.mean(epoch_g_loss))\n",
    "        history['d_loss'].append(np.mean(epoch_d_loss))\n",
    "        history['lr_g'].append(g_lr)\n",
    "        history['lr_d'].append(d_lr)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - {epoch_time:.2f}s - \"\n",
    "              f\"G_loss: {history['g_loss'][-1]:.4f}, D_loss: {history['d_loss'][-1]:.4f}, \"\n",
    "              f\"G_LR: {g_lr:.6f}, D_LR: {d_lr:.6f}\")\n",
    "        \n",
    "        # Periodic evaluation\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            # Generate samples for evaluation\n",
    "            test_noise = tf.random.normal([50, gan.latent_dim])\n",
    "            generated_samples = gan.generator(test_noise, training=False)\n",
    "            generated_samples = 0.5 * generated_samples + 0.5\n",
    "            \n",
    "            # Visual assessment\n",
    "            evaluator.visual_quality_assessment(generated_samples, (5, 5))\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Plot comprehensive training history\n",
    "def plot_training_analysis(histories, model_names):\n",
    "    \"\"\"Plot comprehensive training analysis\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Generator losses\n",
    "    axes[0, 0].set_title('Generator Losses')\n",
    "    for history, name in zip(histories, model_names):\n",
    "        axes[0, 0].plot(history['g_loss'], label=f'{name} Generator')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Discriminator losses\n",
    "    axes[0, 1].set_title('Discriminator Losses')\n",
    "    for history, name in zip(histories, model_names):\n",
    "        axes[0, 1].plot(history['d_loss'], label=f'{name} Discriminator')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss ratio (stability indicator)\n",
    "    axes[0, 2].set_title('Loss Ratio (G_loss / D_loss)')\n",
    "    for history, name in zip(histories, model_names):\n",
    "        if 'd_loss' in history:\n",
    "            ratio = np.array(history['g_loss']) / (np.array(history['d_loss']) + 1e-8)\n",
    "            axes[0, 2].plot(ratio, label=name)\n",
    "    axes[0, 2].axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Ideal Ratio')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Ratio')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning rates (if available)\n",
    "    if 'lr_g' in histories[0]:\n",
    "        axes[1, 0].set_title('Adaptive Learning Rates')\n",
    "        axes[1, 0].plot(histories[0]['lr_g'], label='Generator LR')\n",
    "        axes[1, 0].plot(histories[0]['lr_d'], label='Discriminator LR')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Learning Rate')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training stability\n",
    "    axes[1, 1].set_title('Training Stability')\n",
    "    for history, name in zip(histories, model_names):\n",
    "        stability = np.abs(np.diff(history['g_loss']))\n",
    "        axes[1, 1].plot(stability, label=f'{name} G_loss variance')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss Variance')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Model comparison\n",
    "    axes[1, 2].set_title('Final Performance Comparison')\n",
    "    final_g_losses = [history['g_loss'][-1] for history in histories]\n",
    "    final_d_losses = [history['d_loss'][-1] for history in histories]\n",
    "    \n",
    "    x = np.arange(len(model_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 2].bar(x - width/2, final_g_losses, width, label='Generator Loss', alpha=0.8)\n",
    "    axes[1, 2].bar(x + width/2, final_d_losses, width, label='Discriminator Loss', alpha=0.8)\n",
    "    axes[1, 2].set_xlabel('Models')\n",
    "    axes[1, 2].set_ylabel('Final Loss')\n",
    "    axes[1, 2].set_xticks(x)\n",
    "    axes[1, 2].set_xticklabels(model_names)\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Compare all trained models\n",
    "print(\"=== Training Analysis and Comparison ===\")\n",
    "\n",
    "# Collect all training histories\n",
    "all_histories = [dcgan_history, cgan_history, wgan_history]\n",
    "model_names = ['DCGAN', 'Conditional GAN', 'WGAN-GP']\n",
    "\n",
    "# Plot comprehensive analysis\n",
    "plot_training_analysis(all_histories, model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This comprehensive notebook demonstrated the complete spectrum of GAN implementations using tf.keras:\n",
    "\n",
    "### Key Implementations\n",
    "\n",
    "**1. Basic GAN Architecture:**\n",
    "- Fundamental generator and discriminator concepts\n",
    "- tf.keras Sequential API implementation\n",
    "- Basic adversarial training loop\n",
    "\n",
    "**2. Deep Convolutional GAN (DCGAN):**\n",
    "- Industry-standard architecture with best practices\n",
    "- Optimized training with tf.function decorators\n",
    "- Proper normalization and activation choices\n",
    "\n",
    "**3. Conditional GAN (cGAN):**\n",
    "- tf.keras Functional API for complex inputs\n",
    "- Class-conditional generation capabilities\n",
    "- Label embedding and conditioning techniques\n",
    "\n",
    "**4. Wasserstein GAN-GP (WGAN-GP):**\n",
    "- Gradient penalty for training stability\n",
    "- Critic instead of discriminator (no sigmoid)\n",
    "- Earth Mover's distance optimization\n",
    "\n",
    "**5. Advanced Training Techniques:**\n",
    "- Label smoothing and adaptive learning rates\n",
    "- Feature matching and diversity losses\n",
    "- Spectral normalization and stabilization methods\n",
    "\n",
    "### Technical Achievements\n",
    "\n",
    "- **Stable Training**: WGAN-GP provides most stable training dynamics\n",
    "- **Controlled Generation**: Conditional GANs enable precise control over outputs\n",
    "- **Quality Metrics**: FID and IS scores for objective evaluation\n",
    "- **Production Ready**: Optimized implementations with tf.function\n",
    "\n",
    "### Performance Insights\n",
    "\n",
    "- **DCGAN**: Fast convergence, good for standard image generation\n",
    "- **cGAN**: Excellent controllability, slight complexity overhead\n",
    "- **WGAN-GP**: Most stable, higher computational cost due to gradient penalty\n",
    "- **Advanced Techniques**: Significant improvements in training stability\n",
    "\n",
    "### Applications Demonstrated\n",
    "\n",
    "- Digit generation with MNIST\n",
    "- Class-conditional synthesis\n",
    "- High-resolution image creation\n",
    "- Comprehensive model evaluation and comparison\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue to notebook 14 (VAEs and Advanced GANs) to explore Variational Autoencoders and cutting-edge GAN architectures like StyleGAN and Progressive GANs, building upon the foundational techniques mastered here.\n",
    "\n",
    "The GAN implementations provide a solid foundation for generating high-quality synthetic data across various domains and applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
